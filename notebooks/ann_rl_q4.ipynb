{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdqE-VJ_yqY-",
        "outputId": "74556cc7-0038-4cab-9468-73b944f72bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'public-annrl-files'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 17 (delta 0), reused 17 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), 22.56 KiB | 3.76 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mohahf19/public-annrl-files.git \n",
        "!cp -r public-annrl-files/* .\n",
        "!rm -r public-annrl-files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdKaIa9KZdYB"
      },
      "outputs": [],
      "source": [
        "# # Add the parent directory to path\n",
        "# import sys\n",
        "\n",
        "# sys.path.append(\"..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etI87Mt237pE",
        "outputId": "6987d84a-141f-400f-e75e-7c9065620c5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/epidemic_env/env.py:82: DeprecationWarning: invalid escape sequence '\\('\n",
            "  \"\"\"Computes the reward \\(R(s^{(t)},a^{(t)})\\) from an observation dictionary `obs`:\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from gym import spaces\n",
        "\n",
        "\"\"\"Environment imports\"\"\"\n",
        "from epidemic_env.env import Env, Log\n",
        "from epidemic_env.dynamics import ModelDynamics, Observation\n",
        "from epidemic_env.visualize import Visualize\n",
        "from epidemic_env.agent import Agent\n",
        "\n",
        "\"\"\"Pytorch and numpy imports\"\"\"\n",
        "import numpy as np\n",
        "from typing import Callable\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "import json\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZDtGxRYHyQt",
        "outputId": "1eb9c0a2-ed3c-4349-b5d9-b888e5616819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NpEncoder, self).default(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "oa5IQ95v57Jz",
        "outputId": "c5cbafd2-93ce-4507-e753-cba9981547ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lausanne', 'Geneva', 'Sion', 'Neuchâtel', 'Basel', 'Bern', 'Lücern', 'St-Gallen', 'Zürich']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "dyn = ModelDynamics(\"config/switzerland.yaml\")  # load the switzerland map\n",
        "print(dyn.cities)\n",
        "dyn.draw_map()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh_0_LlF6MGP",
        "outputId": "6f575781-ee7f-4245-a4cc-07d4a59cc985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "['confinement']\n",
            "['hospital']\n",
            "['confinement']\n",
            "['hospital']\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable\n",
        "from copy import deepcopy\n",
        "\n",
        "action = {  # DO NOTHING\n",
        "    \"confinement\": False,\n",
        "    \"isolation\": False,\n",
        "    \"hospital\": False,\n",
        "    \"vaccinate\": False,\n",
        "}\n",
        "\n",
        "# Actually, actions can be any combination of the four.\n",
        "action_value_dict = {0: \"confinement\", 1: \"isolation\", 2: \"hospital\", 3: \"vaccinate\"}\n",
        "\n",
        "# num_actions = 2**1  # If only for confinement\n",
        "num_actions = 5  # Do nothing and toggle 4 actions\n",
        "num_cities = len(dyn.cities)\n",
        "num_features_per_city = 2  # infected, dead\n",
        "\n",
        "num_observation_features = (\n",
        "    num_cities * (num_features_per_city * 7) + 4\n",
        ")  # 4 curr_actions\n",
        "\n",
        "\n",
        "def observation_to_tensor(\n",
        "    obs: Observation,\n",
        "    dyn: ModelDynamics,\n",
        "    curr_action: dict,\n",
        "    features_per_city: int = 7 * num_features_per_city,\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"Convers the observation object to a torch Tensor\n",
        "    The tensor is defined as: for each city, population (1), infected (7), dead (7)\n",
        "    \"\"\"\n",
        "    num_cities = len(dyn.cities)\n",
        "    output = torch.zeros(num_cities * features_per_city + 4)\n",
        "    for i, city in enumerate(dyn.cities):\n",
        "        output[i * features_per_city : i * features_per_city + 7] = (\n",
        "            torch.tensor(obs.city[city].infected) / obs.pop[city]\n",
        "        ) ** (1 / 4)\n",
        "        output[i * features_per_city + 7 : i * features_per_city + 14] = (\n",
        "            torch.tensor(obs.city[city].dead) / obs.pop[city]\n",
        "        ) ** (1 / 4)\n",
        "\n",
        "    # Add the current action to the observation\n",
        "    output[-4] = int(curr_action[\"confinement\"])\n",
        "    output[-3] = int(curr_action[\"isolation\"])\n",
        "    output[-2] = int(curr_action[\"hospital\"])\n",
        "    output[-1] = int(curr_action[\"vaccinate\"])\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "\"\"\"Loading the environment\"\"\"\n",
        "env = Env(\n",
        "    dyn,  # We pass the dynamical model to the environment\n",
        "    action_space=spaces.Discrete(\n",
        "        num_actions\n",
        "    ),  # Here one could pass an openai gym action space that can then be sampled\n",
        "    observation_space=spaces.Box(\n",
        "        low=0, high=np.inf, shape=(num_observation_features,), dtype=float\n",
        "    ),  # Here one could pass an openai gym obs space that can then be sampled\n",
        ")\n",
        "\n",
        "\n",
        "def action_value_to_actions(action_value: int, curr_action: dict) -> list[int]:\n",
        "    if action_value == 0:\n",
        "        return []\n",
        "    str_action = action_value_dict[action_value - 1]\n",
        "\n",
        "    return [str_action]\n",
        "\n",
        "\n",
        "def create_action(\n",
        "    action: int,\n",
        "    curr_action: dict,\n",
        "    action_value_to_actions: Callable = action_value_to_actions,\n",
        "    action_value_dict: dict = action_value_dict,\n",
        ") -> dict[str, bool]:\n",
        "    \"\"\"Creates a policy from the encoded action value\"\"\"\n",
        "    created_actions = action_value_to_actions(action, curr_action)\n",
        "\n",
        "    temp_act = deepcopy(curr_action)\n",
        "\n",
        "    # print(f\"returned action = {created_actions}\")\n",
        "\n",
        "    for act in created_actions:\n",
        "        # print(act)\n",
        "        temp_act[act] = not curr_action[act]\n",
        "\n",
        "    # print(temp_act)\n",
        "    return temp_act\n",
        "\n",
        "\n",
        "tst_actions = {\n",
        "    \"confinement\": False,\n",
        "    \"isolation\": False,\n",
        "    \"hospital\": False,\n",
        "    \"vaccinate\": False,\n",
        "}\n",
        "\n",
        "print(action_value_to_actions(0, tst_actions))\n",
        "\n",
        "print(action_value_to_actions(1, tst_actions))\n",
        "\n",
        "print(action_value_to_actions(3, tst_actions))\n",
        "\n",
        "tst_actions[\"confinement\"] = True\n",
        "\n",
        "print(action_value_to_actions(1, tst_actions))\n",
        "\n",
        "tst_actions[\"hospital\"] = True\n",
        "\n",
        "print(action_value_to_actions(3, tst_actions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt73EXM8ZdYF",
        "outputId": "eb590b9c-b6e9-4470-ae8e-da8fd104c133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation(pop={'Lausanne': 295000, 'Geneva': 900000, 'Sion': 34978, 'Neuchâtel': 44531, 'Basel': 830000, 'Bern': 133115, 'Lücern': 82000, 'St-Gallen': 76213, 'Zürich': 1354000}, city={'Lausanne': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'Geneva': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'Sion': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'Neuchâtel': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'Basel': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'Bern': Observables(infected=[100, 161, 233, 693, 528, 812, 417], dead=[0, 0, 0, 1, 3, 8, 11]), 'Lücern': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'St-Gallen': Observables(infected=[0, 0, 0, 0, 0, 0, 0], dead=[0, 0, 0, 0, 0, 0, 0]), 'Zürich': Observables(infected=[0, 0, 0, 1, 6, 26, 53], dead=[0, 0, 0, 0, 0, 0, 0])}, total=Observables(infected=[100, 161, 233, 694, 534, 838, 470], dead=[0, 0, 0, 1, 3, 8, 11]))\n",
            "{'confinement': True, 'isolation': False, 'hospital': True, 'vaccinate': False}\n",
            "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1656, 0.1865,\n",
            "        0.2045, 0.2686, 0.2510, 0.2795, 0.2366, 0.0000, 0.0000, 0.0000, 0.0524,\n",
            "        0.0689, 0.0880, 0.0953, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0293, 0.0459,\n",
            "        0.0662, 0.0791, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        1.0000, 0.0000, 1.0000, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "# Print observation to tensor example\n",
        "obs, _ = env.reset()\n",
        "print(obs)\n",
        "print(tst_actions)\n",
        "print(observation_to_tensor(obs, dyn, tst_actions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2nOLLSQZdYF",
        "outputId": "ae0dac80-162b-46f8-cf1d-65493799c6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'confinement': False, 'isolation': False, 'hospital': False, 'vaccinate': False}\n",
            "{'confinement': False, 'isolation': False, 'hospital': False, 'vaccinate': False}\n",
            "{'confinement': False, 'isolation': False, 'hospital': False, 'vaccinate': False}\n",
            "{'confinement': True, 'isolation': False, 'hospital': False, 'vaccinate': False}\n",
            "{'confinement': False, 'isolation': False, 'hospital': False, 'vaccinate': False}\n",
            "{'confinement': False, 'isolation': False, 'hospital': True, 'vaccinate': False}\n",
            "{'confinement': False, 'isolation': False, 'hospital': False, 'vaccinate': False}\n",
            "{'confinement': False, 'isolation': False, 'hospital': False, 'vaccinate': True}\n"
          ]
        }
      ],
      "source": [
        "tst_actions = {\n",
        "    \"confinement\": False,\n",
        "    \"isolation\": False,\n",
        "    \"hospital\": False,\n",
        "    \"vaccinate\": False,\n",
        "}\n",
        "\n",
        "print(tst_actions)\n",
        "print(create_action(0, tst_actions))\n",
        "\n",
        "print(tst_actions)\n",
        "print(create_action(1, tst_actions))\n",
        "\n",
        "tst_actions = {\n",
        "    \"confinement\": False,\n",
        "    \"isolation\": False,\n",
        "    \"hospital\": False,\n",
        "    \"vaccinate\": False,\n",
        "}\n",
        "\n",
        "print(tst_actions)\n",
        "print(create_action(3, tst_actions))\n",
        "\n",
        "print(tst_actions)\n",
        "print(create_action(4, tst_actions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWhn1P4e6Teb",
        "outputId": "ec378961-6e75-4d39-9358-5944d0a56c0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1224,  0.1268, -0.0217, -0.1091, -0.0101],\n",
            "        [-0.1155,  0.1414, -0.0513, -0.0806,  0.0096],\n",
            "        [-0.1227,  0.0957, -0.0098, -0.1245, -0.0025],\n",
            "        [-0.1131,  0.1736, -0.0303, -0.1262,  0.0180],\n",
            "        [-0.1001,  0.1478, -0.0286, -0.1008,  0.0045],\n",
            "        [-0.1601,  0.1182, -0.0391, -0.1230, -0.0016],\n",
            "        [-0.1240,  0.1218, -0.0359, -0.0994, -0.0113],\n",
            "        [-0.0689,  0.1303, -0.0411, -0.1117,  0.0289],\n",
            "        [-0.1047,  0.1592, -0.0018, -0.1230, -0.0003],\n",
            "        [-0.1381,  0.1100, -0.0544, -0.0943,  0.0002]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from collections import namedtuple, deque\n",
        "\n",
        "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))\n",
        "\n",
        "\n",
        "class ReplayMemory:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, bs: int):\n",
        "        n_to_sample = bs if bs < len(self.memory) else len(self.memory)\n",
        "        return random.sample(self.memory, n_to_sample)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.memory)\n",
        "    \n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "\n",
        "class DQNModel(nn.Module):\n",
        "    def __init__(self, obs_dim: int, actions_dim: int, activation: str = \"relu\"):\n",
        "        super().__init__()\n",
        "        if activation == \"relu\":\n",
        "            self.activation = nn.ReLU\n",
        "        elif activation == \"tanh\":\n",
        "            self.activation = nn.Tanh\n",
        "        else:\n",
        "            raise ValueError(\"Activation must be either relu or tanh\")\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            # nn.LayerNorm(obs_dim),\n",
        "            nn.Linear(obs_dim, 64),\n",
        "            self.activation(),\n",
        "            nn.Linear(64, 32),\n",
        "            self.activation(),\n",
        "            nn.Linear(32, 16),\n",
        "            self.activation(),\n",
        "            nn.Linear(16, actions_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# Adapt this\n",
        "dqn = DQNModel(env.observation_space.shape[0], num_actions, activation=\"relu\")\n",
        "obs = torch.randn(10, env.observation_space.shape[0])\n",
        "output = dqn(obs)\n",
        "print(output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oZmwnJL46leg"
      },
      "outputs": [],
      "source": [
        "def select_action(output: torch.Tensor, epsilon: float) -> int:\n",
        "    \"\"\"Selects an action based on the output of the DQN.\"\"\"\n",
        "    if np.random.rand() < epsilon:\n",
        "        return np.random.randint(0, len(output))\n",
        "    else:\n",
        "        # print(f' \\n inside select action output = {output} \\n')\n",
        "        # print(f' \\n inside select action argmax = {output.to(\"cpu\").argmax().item()}')\n",
        "        return output.to(\"cpu\").argmax().item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrzHJQzRZdYH",
        "outputId": "bdfdc7a2-42e1-413e-fd9d-5e4a2d6efc37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "select_action(torch.tensor([-0.0800, -0.2345, 0.0702, -0.0823, 0.1156]), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n0VbC91Q6udM"
      },
      "outputs": [],
      "source": [
        "def simulate_policy(\n",
        "        policy_net: nn.Module,\n",
        "        eval_seed_sequences: np.ndarray,\n",
        "        discount_factor: float,\n",
        "        device: str,\n",
        "        logging: bool = False,\n",
        ") -> list[float]:\n",
        "    rewards = []\n",
        "    policy_net.eval()\n",
        "    print_pol = True\n",
        "\n",
        "    for eval_seed in eval_seed_sequences:\n",
        "        cumulative_reward = 0\n",
        "        curr_discount_factor = 1\n",
        "        done = False\n",
        "        obs, info = env.reset(seed=eval_seed)\n",
        "        curr_action = {\n",
        "            \"confinement\": False,\n",
        "            \"isolation\": False,\n",
        "            \"hospital\": False,\n",
        "            \"vaccinate\": False,\n",
        "        }\n",
        "        obs_tensor = observation_to_tensor(obs, dyn, curr_action).to(device)\n",
        "        policy_net.to(device)\n",
        "\n",
        "        while not done:\n",
        "            policy_output = policy_net(obs_tensor)\n",
        "            if print_pol:\n",
        "                print(f'pol_output in simulate = {policy_output.cpu().detach().numpy()}')\n",
        "                print_pol = False\n",
        "            action = select_action(policy_output, epsilon=0)\n",
        "            curr_action = create_action(action, curr_action)\n",
        "            obs, reward, done, info = env.step(curr_action)\n",
        "            obs_tensor = observation_to_tensor(obs, dyn, curr_action).to(device)\n",
        "            if logging:\n",
        "                # print(f\"{action} ({reward.item():.2f})\", end=\" \")\n",
        "                print(action, end=\" \")\n",
        "            reward = reward.to(device)\n",
        "\n",
        "            cumulative_reward += curr_discount_factor * reward\n",
        "            curr_discount_factor *= discount_factor\n",
        "        rewards.append(cumulative_reward.item())\n",
        "        if logging:\n",
        "            print(f\" -> reward: {cumulative_reward.item():.3f}\")\n",
        "            print(info.total)\n",
        "            print()\n",
        "    policy_net.train()\n",
        "\n",
        "    return rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KbnOm9Ss6wTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8805094-ac57-4711-bec8-4233cb05f132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def optimize_model(\n",
        "    policy_net: nn.Module,\n",
        "    target_net: nn.Module,\n",
        "    memory: ReplayMemory,\n",
        "    optimizer: torch.optim,\n",
        "    batch_size: int,\n",
        "    discount_factor: float,\n",
        "    scheduler: optim.lr_scheduler = None,\n",
        "    device: str = \"cpu\",\n",
        ") -> None:\n",
        "    \"\"\"Optimizes the policy network based on a batch of transitions sampled from the replay memory. Only optmise if the replay memory is larger than the batch size.\"\"\"\n",
        "    # assert batch_size <= len(memory), \"Insufficient memory to sample a batch.\"\n",
        "\n",
        "    def criterion(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.nn.MSELoss()(x, y) / (2 * len(x))\n",
        "        # return torch.nn.SmoothL1Loss()(x, y) / (len(x))\n",
        "\n",
        "    transitions = memory.sample(batch_size)\n",
        "\n",
        "    \"\"\"ChatGPT Explanation:\n",
        "    The code batch = Transition(*zip(*transitions)) takes the list of transitions transitions and converts it into a batch of transitions, where each element of the batch is a tuple containing the corresponding elements from all transitions.\n",
        "\n",
        "    Let's break down the code:\n",
        "\n",
        "    zip(*transitions) takes all the transitions and groups together all elements at the same position in each tuple, effectively transposing the list of tuples. For example, if the original transitions list contains (s1, a1, s2, r1) and (s2, a2, s3, r2), the result of zip(*transitions) will be (s1, s2), (a1, a2), (s2, s3), (r1, r2).\n",
        "\n",
        "    * before zip unpacks the list transitions into separate arguments to zip.\n",
        "\n",
        "    Transition(*zip(*transitions)) uses argument unpacking again, but this time for the Transition namedtuple. It unpacks the resulting tuples of zip(*transitions) into four separate arguments (state, action, next_state, reward) and creates a new instance of Transition for each element in the batch.\n",
        "\n",
        "    So, batch is a namedtuple of batches, where each element in the batch corresponds to all states, actions, next_states and rewards from all the transitions. For example, if the original transitions list contains three transitions, then batch.state would be a tuple of the three states, batch.action would be a tuple of the three actions, and so on.\n",
        "    \"\"\"\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    state_b = torch.stack(batch.state).to(device)\n",
        "    next_state_b = torch.stack(batch.next_state).to(device)\n",
        "    action_b = torch.tensor(batch.action).to(device)\n",
        "    reward_b = torch.tensor(batch.reward).to(device)\n",
        "\n",
        "    policy_net.to(device)\n",
        "    target_net.to(device)\n",
        "\n",
        "    state_action_values = policy_net(state_b).gather(\n",
        "        1, action_b.unsqueeze(1)\n",
        "    )  # Computes Q_theta(s_t, a_t)\n",
        "    next_state_values = target_net(next_state_b).max(1)[\n",
        "        0\n",
        "    ]  # Computes \\hat{Q}(s_t+1) = max_a \\hat{Q}(s_t+1, a)\n",
        "\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * discount_factor) + reward_b\n",
        "\n",
        "    loss = criterion(\n",
        "        expected_state_action_values, state_action_values.squeeze()\n",
        "    )  # Difference between the expected Q values and the actual Q values\n",
        "    # loss = expected_state_action_values - state_action_values.squeeze() # Difference between the expected Q values and the actual Q values\n",
        "\n",
        "    # Optimize the model now\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def compute_epsilon(\n",
        "    e_initial: float, e_min: float, total_steps: int, current_steps: int\n",
        ") -> float:\n",
        "    return max(e_min, e_initial * (total_steps - current_steps) / total_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KluAANBZdYN",
        "outputId": "fdb2bce5-b96e-4d67-f332-23b9f027e2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def set_new_learning_rate(optimizer, learning_rate, num_episode, compute_new_learning_rate):\n",
        "    new_learning_rate = compute_new_learning_rate(num_episode)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = new_learning_rate\n",
        "    return new_learning_rate\n",
        "        \n",
        "def run_train_experiment(load_cache, num_episodes, seed, learning_rate, compute_new_learning_rate, \n",
        "                         discount_factor, target_update_per, evaluate_per, eval_seed_sequences, \n",
        "                         batch_size, buffer_size, epsilon_min, epsilon_init, device, \n",
        "                         run_id):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    num_eval_episodes = len(eval_seed_sequences)\n",
        "    env_seed_sequences = np.random.randint(0, 1000, size=num_episodes)\n",
        "\n",
        "    assert len(env_seed_sequences) == num_episodes\n",
        "\n",
        "\n",
        "    ## Initializations\n",
        "    obs, info = env.reset(seed=seed)\n",
        "    n_actions = env.action_space.n\n",
        "    mock_actions = {\n",
        "        \"confinement\": False,\n",
        "        \"isolation\": False,\n",
        "        \"hospital\": False,\n",
        "        \"vaccinate\": False,\n",
        "    }\n",
        "    n_observations = observation_to_tensor(obs, dyn, mock_actions).shape[0]\n",
        "\n",
        "\n",
        "    model_save_path = Path(\"models\")\n",
        "    model_save_path.mkdir(exist_ok=True)\n",
        "    best_model_path = model_save_path / f\"dqn_{run_id}_best.pt\"\n",
        "\n",
        "\n",
        "    ## Policy and target networks\n",
        "    if load_cache:\n",
        "        print(\"Loading from cache\")\n",
        "        policy_net = DQNModel(n_observations, n_actions).to(device)\n",
        "        policy_net.load_state_dict(torch.load(best_model_path))\n",
        "        target_net = DQNModel(n_observations, n_actions).to(device)\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "    else:\n",
        "        print(\"Creating new models..\")\n",
        "        policy_net = DQNModel(n_observations, n_actions).to(device)\n",
        "        target_net = DQNModel(n_observations, n_actions).to(device)\n",
        "        target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    memory = ReplayMemory(buffer_size)\n",
        "    optimizer = optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
        "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
        "    scheduler = None\n",
        "\n",
        "    tr_losses = []\n",
        "    learning_rates = []\n",
        "\n",
        "    tr_trace, eval_trace_mean, eval_trace_std = [], [], []\n",
        "    has_logged_started_training_message = False\n",
        "\n",
        "    best_eval_reward = -np.inf\n",
        "\n",
        "\n",
        "    for num_episode in range(num_episodes):\n",
        "        lr = set_new_learning_rate(optimizer, learning_rate, num_episode, compute_new_learning_rate)\n",
        "        obs, info = env.reset(seed=env_seed_sequences[num_episode])\n",
        "        curr_action = {\n",
        "            \"confinement\": False,\n",
        "            \"isolation\": False,\n",
        "            \"hospital\": False,\n",
        "            \"vaccinate\": False,\n",
        "        }\n",
        "        obs_tensor = observation_to_tensor(obs, dyn, curr_action).to(device)\n",
        "\n",
        "        done = False\n",
        "\n",
        "        cumulative_tr_reward = 0\n",
        "        curr_discount_factor = 1\n",
        "        ep_losses = []\n",
        "\n",
        "        # print_week = True\n",
        "\n",
        "        while not done:  # play the episode\n",
        "            policy_output = policy_net(obs_tensor)\n",
        "            # if print_week:\n",
        "            #     print(f'pol_output = {policy_output}')\n",
        "            #     print_week = False\n",
        "            action = select_action(\n",
        "                policy_output,\n",
        "                epsilon=compute_epsilon(\n",
        "                    epsilon_init, epsilon_min, num_episodes, num_episode\n",
        "                ),\n",
        "            )\n",
        "\n",
        "            curr_action = create_action(action, curr_action)\n",
        "\n",
        "            obs, reward, done, info = env.step(curr_action)\n",
        "            new_obs_tensor = observation_to_tensor(obs, dyn, curr_action).to(device)\n",
        "            reward = reward.to(device)\n",
        "\n",
        "            memory.push(obs_tensor, action, new_obs_tensor, reward)\n",
        "            obs_tensor = new_obs_tensor\n",
        "\n",
        "            cumulative_tr_reward += curr_discount_factor * reward\n",
        "            curr_discount_factor *= discount_factor\n",
        "\n",
        "            if batch_size <= len(memory):\n",
        "                if not has_logged_started_training_message:\n",
        "                    print(\"Started training\")\n",
        "                    has_logged_started_training_message = True\n",
        "\n",
        "                loss_val = optimize_model(\n",
        "                    policy_net,\n",
        "                    target_net,\n",
        "                    memory,\n",
        "                    optimizer,\n",
        "                    batch_size,\n",
        "                    discount_factor,\n",
        "                    device=device,\n",
        "                    scheduler=scheduler,\n",
        "                )\n",
        "                tr_losses.append(loss_val)\n",
        "                ep_losses.append(loss_val)\n",
        "                learning_rates.append(lr)\n",
        "                # print(loss_val)\n",
        "\n",
        "            # loss_val = optimize_model(policy_net, target_net, memory, optimizer, batch_size, discount_factor, device=device)\n",
        "            # tr_losses.append(loss_val)\n",
        "        tr_trace.append(cumulative_tr_reward.item())\n",
        "        print(f\"Episode {num_episode} | Reward: {cumulative_tr_reward.item():.2f} | Mean loss: {np.mean(ep_losses):.5f}, learning rate: {optimizer.param_groups[0]['lr']:1.1e}\")\n",
        "\n",
        "        if num_episode % target_update_per == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "        if num_episode % evaluate_per == 0 or num_episode == num_episodes - 1:\n",
        "            eval_rewards = simulate_policy(\n",
        "                policy_net,\n",
        "                eval_seed_sequences,\n",
        "                discount_factor=discount_factor,\n",
        "                device=device,\n",
        "            )  # one reward per eval episode, so a 20 length list\n",
        "            eval_trace_mean.append(np.mean(eval_rewards))\n",
        "            eval_trace_std.append(np.std(eval_rewards))\n",
        "            print(\n",
        "                f\"Episode {num_episode} | Eval reward mean: {np.mean(eval_rewards):.2f} | Eval reward std: {np.std(eval_rewards):.5}\"\n",
        "            )\n",
        "\n",
        "            if np.mean(eval_rewards) >= best_eval_reward:\n",
        "                # update the best reward and save the model\n",
        "                print(f\"Saved best model 😏\")\n",
        "                best_eval_reward = np.mean(eval_rewards)\n",
        "                torch.save(policy_net.state_dict(), best_model_path)\n",
        "    metrics_path = model_save_path / f\"dqn_{run_id}_metrics.json\"\n",
        "    with open(metrics_path, \"w\") as f:\n",
        "        json.dump({\"tr_trace\":tr_trace, \"eval_trace_mean\": eval_trace_mean,\n",
        "                   \"eval_trace_std\":eval_trace_std, \"tr_losses\":tr_losses,\n",
        "                   \"eval_seed_sequences\": eval_seed_sequences,\n",
        "                   \"learning_rates\": learning_rates},\n",
        "                  f,\n",
        "                  cls=NpEncoder)\n",
        "    return policy_net, tr_trace, eval_trace_mean, tr_losses, learning_rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuVv1PXMJcbx",
        "outputId": "7d8b2432-7267-4f14-dc8f-5b974ab9b6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on run_id = 1\n",
            "Creating new models..\n",
            "Episode 0 | Reward: -57.47 | Mean loss: nan, learning rate: 1.0e-01\n",
            "pol_output in simulate = [-0.1170189  -0.24864565  0.02478737 -0.11810161 -0.11819771]\n",
            "Episode 0 | Eval reward mean: -179.95 | Eval reward std: 47.203\n",
            "Saved best model 😏\n",
            "Episode 1 | Reward: -151.53 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 2 | Reward: -91.65 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 3 | Reward: -14.69 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 4 | Reward: -101.38 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 5 | Reward: -6.30 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 6 | Reward: -98.60 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 7 | Reward: -200.92 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 8 | Reward: -95.61 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 9 | Reward: -57.43 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 10 | Reward: -44.51 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 11 | Reward: -147.92 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 12 | Reward: -134.70 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 13 | Reward: -51.17 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 14 | Reward: -91.30 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 15 | Reward: -55.02 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 16 | Reward: -170.23 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 17 | Reward: -43.99 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 18 | Reward: -145.13 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 19 | Reward: -17.77 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 20 | Reward: -124.14 | Mean loss: nan, learning rate: 1.0e-01\n",
            "pol_output in simulate = [-0.1170189  -0.24864565  0.02478737 -0.11810161 -0.11819771]\n",
            "Episode 20 | Eval reward mean: -179.95 | Eval reward std: 47.203\n",
            "Saved best model 😏\n",
            "Episode 21 | Reward: -20.32 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 22 | Reward: -54.74 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 23 | Reward: -69.52 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 24 | Reward: -73.86 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 25 | Reward: -20.30 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 26 | Reward: -61.85 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 27 | Reward: -12.93 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 28 | Reward: -113.38 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 29 | Reward: -194.45 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 30 | Reward: -62.79 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 31 | Reward: -104.78 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 32 | Reward: -78.65 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 33 | Reward: -95.57 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 34 | Reward: -27.40 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 35 | Reward: -25.32 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 36 | Reward: -37.72 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 37 | Reward: -18.81 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 38 | Reward: -54.66 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 39 | Reward: -93.92 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 40 | Reward: -53.46 | Mean loss: nan, learning rate: 1.0e-01\n",
            "pol_output in simulate = [-0.1170189  -0.24864565  0.02478737 -0.11810161 -0.11819771]\n",
            "Episode 40 | Eval reward mean: -179.95 | Eval reward std: 47.203\n",
            "Saved best model 😏\n",
            "Episode 41 | Reward: -19.59 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 42 | Reward: -24.71 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 43 | Reward: -93.66 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 44 | Reward: -67.77 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 45 | Reward: -140.25 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 46 | Reward: -42.89 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 47 | Reward: -110.13 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 48 | Reward: -64.76 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 49 | Reward: -24.89 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 50 | Reward: -64.76 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 51 | Reward: -14.83 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 52 | Reward: -202.17 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 53 | Reward: -15.27 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 54 | Reward: -28.94 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 55 | Reward: -51.01 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 56 | Reward: -121.77 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 57 | Reward: -19.89 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 58 | Reward: -201.12 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 59 | Reward: -175.36 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 60 | Reward: -93.22 | Mean loss: nan, learning rate: 1.0e-01\n",
            "pol_output in simulate = [-0.1170189  -0.24864565  0.02478737 -0.11810161 -0.11819771]\n",
            "Episode 60 | Eval reward mean: -179.95 | Eval reward std: 47.203\n",
            "Saved best model 😏\n",
            "Episode 61 | Reward: -130.43 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 62 | Reward: -48.93 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 63 | Reward: -88.43 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 64 | Reward: -14.36 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 65 | Reward: -80.31 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 66 | Reward: -91.71 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Episode 67 | Reward: -14.68 | Mean loss: nan, learning rate: 1.0e-01\n",
            "Started training\n",
            "Episode 68 | Reward: 1.45 | Mean loss: 0.04054, learning rate: 1.0e-01\n",
            "Episode 69 | Reward: -9.38 | Mean loss: 0.01767, learning rate: 1.0e-01\n",
            "Episode 70 | Reward: -94.60 | Mean loss: 0.01083, learning rate: 1.0e-01\n",
            "Episode 71 | Reward: -60.51 | Mean loss: 0.01108, learning rate: 1.0e-01\n",
            "Episode 72 | Reward: -42.47 | Mean loss: 0.00576, learning rate: 1.0e-01\n",
            "Episode 73 | Reward: -60.83 | Mean loss: 0.00459, learning rate: 1.0e-01\n",
            "Episode 74 | Reward: -111.13 | Mean loss: 0.00465, learning rate: 1.0e-01\n",
            "Episode 75 | Reward: -83.43 | Mean loss: 0.00490, learning rate: 1.0e-01\n",
            "Episode 76 | Reward: -18.10 | Mean loss: 0.01144, learning rate: 1.0e-01\n",
            "Episode 77 | Reward: -71.25 | Mean loss: 0.00555, learning rate: 1.0e-01\n",
            "Episode 78 | Reward: -4.39 | Mean loss: 0.00430, learning rate: 1.0e-01\n",
            "Episode 79 | Reward: -50.77 | Mean loss: 0.00390, learning rate: 1.0e-01\n",
            "Episode 80 | Reward: -126.05 | Mean loss: 0.00426, learning rate: 1.0e-01\n",
            "pol_output in simulate = [-29.356052 -12.388022 -31.200409 -33.88476  -33.50438 ]\n",
            "Episode 80 | Eval reward mean: -3.42 | Eval reward std: 7.9385\n",
            "Saved best model 😏\n",
            "Episode 81 | Reward: -31.33 | Mean loss: 0.00543, learning rate: 1.0e-01\n",
            "Episode 82 | Reward: -9.11 | Mean loss: 0.00403, learning rate: 1.0e-01\n",
            "Episode 83 | Reward: -40.37 | Mean loss: 0.00411, learning rate: 1.0e-01\n",
            "Episode 84 | Reward: -119.55 | Mean loss: 0.00429, learning rate: 1.0e-01\n",
            "Episode 85 | Reward: 3.91 | Mean loss: 0.00414, learning rate: 1.0e-01\n",
            "Episode 86 | Reward: -51.12 | Mean loss: 0.00559, learning rate: 1.0e-01\n",
            "Episode 87 | Reward: 6.91 | Mean loss: 0.00481, learning rate: 1.0e-01\n",
            "Episode 88 | Reward: -77.35 | Mean loss: 0.00478, learning rate: 1.0e-01\n",
            "Episode 89 | Reward: -28.02 | Mean loss: 0.00462, learning rate: 1.0e-01\n",
            "Episode 90 | Reward: -31.74 | Mean loss: 0.00419, learning rate: 1.0e-01\n",
            "Episode 91 | Reward: -27.21 | Mean loss: 0.00576, learning rate: 1.0e-01\n",
            "Episode 92 | Reward: -25.77 | Mean loss: 0.00473, learning rate: 1.0e-01\n",
            "Episode 93 | Reward: -17.98 | Mean loss: 0.00433, learning rate: 1.0e-01\n",
            "Episode 94 | Reward: -12.27 | Mean loss: 0.00425, learning rate: 1.0e-01\n",
            "Episode 95 | Reward: -5.10 | Mean loss: 0.00444, learning rate: 1.0e-01\n",
            "Episode 96 | Reward: -71.66 | Mean loss: 0.01101, learning rate: 1.0e-01\n",
            "Episode 97 | Reward: -36.64 | Mean loss: 0.00589, learning rate: 1.0e-01\n",
            "Episode 98 | Reward: -20.59 | Mean loss: 0.00470, learning rate: 1.0e-01\n",
            "Episode 99 | Reward: -17.27 | Mean loss: 0.00441, learning rate: 1.0e-01\n",
            "Episode 100 | Reward: -25.78 | Mean loss: 0.00475, learning rate: 1.0e-02\n",
            "pol_output in simulate = [-23.937365  -7.495986 -22.945793 -34.989685 -21.016325]\n",
            "Episode 100 | Eval reward mean: 3.55 | Eval reward std: 10.952\n",
            "Saved best model 😏\n",
            "Episode 101 | Reward: -10.26 | Mean loss: 0.00571, learning rate: 1.0e-02\n",
            "Episode 102 | Reward: -16.80 | Mean loss: 0.00512, learning rate: 1.0e-02\n",
            "Episode 103 | Reward: -16.33 | Mean loss: 0.00509, learning rate: 1.0e-02\n",
            "Episode 104 | Reward: -64.08 | Mean loss: 0.00523, learning rate: 1.0e-02\n",
            "Episode 105 | Reward: -13.51 | Mean loss: 0.00524, learning rate: 1.0e-02\n",
            "Episode 106 | Reward: -6.18 | Mean loss: 0.00603, learning rate: 1.0e-02\n"
          ]
        }
      ],
      "source": [
        "run_ids = [(1, \"q4a_1_changing\"), (2, \"q4a_2_changing\"), (3, \"q4a_3_changing\")]\n",
        "\n",
        "load_cache = False\n",
        "num_episodes = 500\n",
        "\n",
        "first_learning_rate = 1e-1\n",
        "\n",
        "def compute_new_learning_rate(num_episode):\n",
        "    if num_episode < 100:\n",
        "        return 1e-1\n",
        "    elif num_episode < 200:\n",
        "        return 1e-2\n",
        "    elif num_episode < 300:\n",
        "        return 1e-3\n",
        "    elif num_episode < 400:\n",
        "        return 1e-4\n",
        "    else:\n",
        "        return 1e-5\n",
        "\n",
        "discount_factor = 0.9\n",
        "target_update_per = 5  # update target network every 5 episodes\n",
        "evaluate_per = 20  # evaluate every 20 episodes\n",
        "num_eval_episodes = 20\n",
        "batch_size = 2 ** 11\n",
        "buffer_size  = 20_000\n",
        "epsilon_min = 0.2\n",
        "epsilon_init = 0.7\n",
        "device = \"cuda\"\n",
        "\n",
        "run_data = {}\n",
        "for run_id, run_name in run_ids:\n",
        "    print(f\"Working on run_id = {run_id}\")\n",
        "    seed = 41 + run_id\n",
        "    np.random.seed(seed)\n",
        "    eval_seed_sequences = np.random.randint(0, 1000, size=num_eval_episodes)\n",
        "\n",
        "    policy_net, tr_trace, eval_trace_mean, tr_losses, learning_rates = run_train_experiment(load_cache, num_episodes, \n",
        "                                                            seed, first_learning_rate, compute_new_learning_rate,\n",
        "                                                            discount_factor, \n",
        "                                                            target_update_per, evaluate_per, \n",
        "                                                            eval_seed_sequences, batch_size, buffer_size, \n",
        "                                                            epsilon_min, epsilon_init, device, run_name)\n",
        "    run_data[run_id] = (policy_net, tr_trace, eval_trace_mean, tr_losses,eval_seed_sequences, learning_rates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BXPyZhmbRpi"
      },
      "outputs": [],
      "source": [
        "policy_net, tr_trace, eval_trace_mean, tr_losses,eval_seed_sequences, learning_rates = run_data[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKXk4V3DBDDx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYvuH8fN8Afj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "ax[0].plot(tr_trace, label=\"training rewards\")\n",
        "ax[0].set_title(\"Training trace\")\n",
        "\n",
        "ax[1].plot(eval_trace_mean, label=\"eval mean reward\")\n",
        "ax[1].set_title(\"Eval trace\")\n",
        "\n",
        "fig.suptitle(\"DQN rewards\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EZkAU7t-IXA"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "\n",
        "ax.plot(tr_losses, label=\"Training loss\", color=\"tab:blue\")\n",
        "\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(learning_rates,  label = \"Learning rates\", color=\"tab:orange\")\n",
        "ax2.set_yscale(\"log\")\n",
        "\n",
        "fig.legend()\n",
        "fig.suptitle(\"Training loss and learning rates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Izo0T2H-Ip1"
      },
      "outputs": [],
      "source": [
        "print(\"1 means confine, 0 means no action\")\n",
        "eval_rewards = simulate_policy(policy_net, eval_seed_sequences, discount_factor=discount_factor, device=device, logging=True)\n",
        "print(eval_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2RG9gom_N1e"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"models/data.pkl\", \"wb\") as f:\n",
        "    pickle.dump(run_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix66ZjVuGvWu"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/models /content/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txVgaz5NGzVQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/models.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHOsZtZgdAhr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}